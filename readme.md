Facial Emotion Recognition – Happy vs Sad

Ce projet consiste à développer une application web de reconnaissance des émotions faciales capable de classifier deux émotions principales : Happy et Sad. L’objectif est d’explorer concrètement l’utilisation de l’intelligence artificielle et du deep learning dans un contexte de vision par ordinateur, tout en mettant en place un pipeline complet allant de la préparation des données jusqu’au déploiement d’un modèle fonctionnel via une interface web.
Le projet s’inscrit dans un cadre académique et vise à consolider les notions fondamentales liées à la classification d’images, à l’apprentissage profond et à l’intégration d’un modèle d’IA dans une application réelle. Malgré la simplicité volontaire du nombre d’émotions, le travail réalisé couvre l’ensemble des étapes essentielles d’un projet en intelligence artificielle.
Le modèle utilisé est un réseau de neurones convolutionnel (CNN) développé à l’aide de TensorFlow et Keras. Il a été entraîné sur un dataset d’images faciales contenant plusieurs émotions, dont seules les classes Happy et Sad ont été sélectionnées. Les images ont subi un prétraitement incluant le redimensionnement, la conversion en niveaux de gris et la normalisation des pixels afin d’assurer une cohérence entre les données d’entraînement et les images testées par l’utilisateur. Le modèle a été entraîné sur 50 epochs afin d’améliorer la capacité de généralisation.
Les données ont été organisées de manière structurée en ensembles d’entraînement et de test, chacun subdivisé selon les deux émotions ciblées. Cette organisation a permis de faciliter l’apprentissage du modèle ainsi que l’évaluation de ses performances. Une attention particulière a été portée à la cohérence entre la structure du dataset et le code d’entraînement afin d’éviter toute incohérence lors de l’apprentissage.
Une application web a ensuite été développée à l’aide du framework Flask. Cette application permet à l’utilisateur de téléverser une image faciale, qui est automatiquement prétraitée avant d’être transmise au modèle pour prédiction. Le résultat de la classification est ensuite affiché de manière claire et intuitive. Un effort particulier a été consacré à l’amélioration de l’interface utilisateur à travers un design moderne, des animations, des effets visuels et des boutons interactifs afin de rendre l’application plus attractive et conviviale.
Tout au long du développement, plusieurs difficultés ont été rencontrées. Le modèle donnait initialement de bons résultats sur les images issues du dataset, mais des prédictions incorrectes apparaissaient lors de l’utilisation d’images externes provenant d’internet. Ce problème a mis en évidence l’importance du prétraitement des données et de l’harmonisation entre les images d’entraînement et celles utilisées en production. Des ajustements ont été effectués afin de réduire cet écart, notamment en appliquant systématiquement les mêmes transformations aux images importées par l’utilisateur.
Des difficultés techniques liées à l’environnement de développement ont également été rencontrées, notamment concernant l’installation et la gestion des bibliothèques Python telles que TensorFlow et OpenCV, ainsi que la configuration de l’environnement virtuel. Ces problèmes ont permis de mieux comprendre l’importance de la gestion des dépendances et de la séparation entre le code source et l’environnement d’exécution.
Enfin, des problèmes sont apparus lors de la mise en ligne du projet sur GitHub, notamment en raison de la présence de fichiers volumineux tels que l’environnement virtuel et les datasets compressés. Ces difficultés ont conduit à une restructuration complète du projet et à la création d’un dépôt propre, intégrant un fichier .gitignore afin d’exclure les fichiers lourds et inutiles. Cette étape a permis de publier le projet de manière professionnelle et conforme aux bonnes pratiques.
Ce projet m’a permis d’acquérir une expérience concrète et complète en intelligence artificielle appliquée, allant bien au-delà de l’aspect théorique. Il constitue une base solide pouvant être enrichie à l’avenir par l’ajout de nouvelles émotions, l’amélioration du modèle ou l’intégration de techniques plus avancées de détection et d’analyse faciale.
